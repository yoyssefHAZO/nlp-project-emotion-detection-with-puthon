{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fadc6a7",
   "metadata": {},
   "source": [
    "# Importing The Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2ad563d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog posts amount criticism hea...</td>\n",
       "      <td>‚òπÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>üôÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not feeling super well turns cold knocked next...</td>\n",
       "      <td>üôÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talents</td>\n",
       "      <td>üôÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>‚òπÔ∏è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0  carefully word blog posts amount criticism hea...      ‚òπÔ∏è\n",
       "1  cannot remember little mermaid feeling carefre...       üôÇ\n",
       "2  not feeling super well turns cold knocked next...       üôÇ\n",
       "3            feel honored part group amazing talents       üôÇ\n",
       "4  think helping also began feel pretty lonely lo...      ‚òπÔ∏è"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textblob\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install textblob\n",
    "#!python -m textblob.download_corpora\n",
    "data = pd.read_csv('F:/Datasets/NLP/Project 2/Text_Emotion.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4b9db42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog posts amount criticism hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not feeling super well turns cold knocked next...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  carefully word blog posts amount criticism hea...        0\n",
       "1  cannot remember little mermaid feeling carefre...        1\n",
       "2  not feeling super well turns cold knocked next...        1\n",
       "3            feel honored part group amazing talents        1\n",
       "4  think helping also began feel pretty lonely lo...        0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning The Emojis with 'Happy': 1, 'Sad': 0\n",
    "data['emotion'] = data['emotion'].map({\n",
    "    '‚òπÔ∏è' : 0,\n",
    "    'üôÇ' : 1\n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0dc98",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae15d922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog posts amount criticism hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feeling super well turns cold knocked next thr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  carefully word blog posts amount criticism hea...        0\n",
       "1  cannot remember little mermaid feeling carefre...        1\n",
       "2  feeling super well turns cold knocked next thr...        1\n",
       "3            feel honored part group amazing talents        1\n",
       "4  think helping also began feel pretty lonely lo...        0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making all text lower case\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "\n",
    "# Removing all punctuations and stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
    "\n",
    "#Punctuations\n",
    "from string import punctuation\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in punctuation))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ca2f1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog post amount criticism hear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feeling super well turn cold knocked next thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  carefully word blog post amount criticism hear...        0\n",
       "1  cannot remember little mermaid feeling carefre...        1\n",
       "2  feeling super well turn cold knocked next thre...        1\n",
       "3             feel honored part group amazing talent        1\n",
       "4  think helping also began feel pretty lonely lo...        0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatisation\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from textblob import Word\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "# Correcting letter repetitions\n",
    "import re\n",
    "def no_repeats(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(no_repeats(x) for x in x.split()))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3fd16edf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1931334565.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[158], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def cleaning (text):\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def cleaning (text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "14356bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog post amount criticism hear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feeling super well turn cold knocked next thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  carefully word blog post amount criticism hear...        0\n",
       "1  cannot remember little mermaid feeling carefre...        1\n",
       "2  feeling super well turn cold knocked next thre...        1\n",
       "3             feel honored part group amazing talent        1\n",
       "4  think helping also began feel pretty lonely lo...        0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the rarest words\n",
    "freq = pd.Series(' '.join(data['text']).split()).value_counts()[-10000:]\n",
    "\n",
    "# Removing rarely appearing words\n",
    "freq = list(freq.index)\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join(x for x in x.split() if x not in freq))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f3162",
   "metadata": {},
   "source": [
    "# Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8c3a07f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275410                           take tablet feel suffering\n",
       "212955    feel like life shamble since accutane determin...\n",
       "210948                       abstain feel dull boring small\n",
       "69462     dislike used patriarchal system way really obj...\n",
       "52496     suffering depression miserable job feeling pre...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = data['emotion']\n",
    "data1 = data['text']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data1, labels, test_size=0.33, shuffle=True)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e1e2d",
   "metadata": {},
   "source": [
    "# Extracting The TF-IDF Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "173a4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "X_train_tfidf = tfidf.fit_transform(x_train)\n",
    "X_val_tfidf = tfidf.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618fb446",
   "metadata": {},
   "source": [
    "# Extracting The Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e3eb5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data1)\n",
    "X_train_count =  count_vect.transform(x_train)\n",
    "X_val_count =  count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7241a1b",
   "metadata": {},
   "source": [
    "# Trying Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eefd33dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes count vectors accuracy 0.9432884755496507\n",
      "naive bayes count vectors accuracy 0.5540329147559251\n"
     ]
    }
   ],
   "source": [
    "# With Count Vectors\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_count, y_train)\n",
    "y_pred = nb.predict(X_val_count)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "\n",
    "# With TF-IDF\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred = nb.predict(X_val_tfidf)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c0bc0",
   "metadata": {},
   "source": [
    "# Trying Linear SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f796fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.9359705138644838\n",
      "naive bayes count vectors accuracy 0.5737046243517765\n"
     ]
    }
   ],
   "source": [
    "# With Count Vectors\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "\n",
    "# With TF-IDF\n",
    "lsvm.fit(X_train_tfidf, y_train)\n",
    "y_pred = lsvm.predict(X_val_tfidf)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544529f8",
   "metadata": {},
   "source": [
    "# Trying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b37a08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeLL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg count vectors accuracy 0.9585136930527579\n",
      "naive bayes count vectors accuracy 0.5678223974628209\n"
     ]
    }
   ],
   "source": [
    "# With Count Vectors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_count, y_train)\n",
    "y_pred = logreg.predict(X_val_count)\n",
    "print('log reg count vectors accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "\n",
    "# With TF-IDF\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_val_tfidf)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bcb8b",
   "metadata": {},
   "source": [
    "# Tokenization and Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "eec44bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization & sequencing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e356079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 50333 Unique Tokens\n"
     ]
    }
   ],
   "source": [
    "V = len(tokenizer.index_word)\n",
    "print(\"Tokenized %s Unique Tokens\" %V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "818be211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 5259,    1,  362],\n",
       "       [   0,    0,    0, ...,    9,    4,  111],\n",
       "       [   0,    0,    0, ...,  298,  290,  526],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   99,  114,  428],\n",
       "       [   0,    0,    0, ..., 2670,   38,  448],\n",
       "       [   0,    0,    0, ...,  922,  834, 9414]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Padding\n",
    "data_train = pad_sequences(sequence_train)\n",
    "\n",
    "T = data_train.shape[1]\n",
    "\n",
    "data_test = pad_sequences(sequence_test, maxlen=T)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9c1d226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, Embedding, MaxPooling1D, GlobalMaxPooling1D, Add, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "D = 20\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1 , D)(i)\n",
    "x = Conv1D(32, 3, padding='same',activation=LeakyReLU(alpha=0.2))(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(64, 3, padding='same', activation=LeakyReLU(alpha=0.2))(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, padding='same', activation=LeakyReLU(alpha=0.2))(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='relu')(x)\n",
    "\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "44f3aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.0002\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "19ef5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5922/5922 [==============================] - 80s 12ms/step - loss: 0.3679 - accuracy: 0.8138 - val_loss: 0.2115 - val_accuracy: 0.8978\n",
      "Epoch 2/15\n",
      "5922/5922 [==============================] - 60s 10ms/step - loss: 0.2166 - accuracy: 0.9040 - val_loss: 0.2105 - val_accuracy: 0.8986\n",
      "Epoch 3/15\n",
      "5922/5922 [==============================] - 61s 10ms/step - loss: 0.1962 - accuracy: 0.9143 - val_loss: 0.2047 - val_accuracy: 0.9008\n",
      "Epoch 4/15\n",
      "5922/5922 [==============================] - 61s 10ms/step - loss: 0.1906 - accuracy: 0.9168 - val_loss: 0.2020 - val_accuracy: 0.8949\n",
      "Epoch 5/15\n",
      "5922/5922 [==============================] - 61s 10ms/step - loss: 0.1924 - accuracy: 0.9222 - val_loss: 0.2556 - val_accuracy: 0.8969\n",
      "Epoch 6/15\n",
      "5922/5922 [==============================] - 65s 11ms/step - loss: 0.1672 - accuracy: 0.9317 - val_loss: 0.2669 - val_accuracy: 0.9006\n",
      "Epoch 7/15\n",
      "5922/5922 [==============================] - 72s 12ms/step - loss: 0.1595 - accuracy: 0.9384 - val_loss: 0.2800 - val_accuracy: 0.8985\n",
      "Epoch 8/15\n",
      "5922/5922 [==============================] - 66s 11ms/step - loss: 0.1419 - accuracy: 0.9450 - val_loss: 0.3730 - val_accuracy: 0.8988\n",
      "Epoch 9/15\n",
      "5922/5922 [==============================] - 66s 11ms/step - loss: 0.1361 - accuracy: 0.9476 - val_loss: 0.3444 - val_accuracy: 0.8960\n",
      "Epoch 10/15\n",
      "5922/5922 [==============================] - 67s 11ms/step - loss: 0.1351 - accuracy: 0.9504 - val_loss: 0.4032 - val_accuracy: 0.8899\n",
      "Epoch 11/15\n",
      "5922/5922 [==============================] - 66s 11ms/step - loss: 0.1457 - accuracy: 0.9508 - val_loss: 0.4375 - val_accuracy: 0.8946\n",
      "Epoch 12/15\n",
      "5922/5922 [==============================] - 68s 11ms/step - loss: 0.1159 - accuracy: 0.9571 - val_loss: 0.4636 - val_accuracy: 0.8930\n",
      "Epoch 13/15\n",
      "5922/5922 [==============================] - 69s 12ms/step - loss: 0.1134 - accuracy: 0.9591 - val_loss: 0.5271 - val_accuracy: 0.8952\n",
      "Epoch 14/15\n",
      "5922/5922 [==============================] - 69s 12ms/step - loss: 0.1102 - accuracy: 0.9615 - val_loss: 0.5859 - val_accuracy: 0.8941\n",
      "Epoch 15/15\n",
      "5922/5922 [==============================] - 69s 12ms/step - loss: 0.1086 - accuracy: 0.9630 - val_loss: 0.6290 - val_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    data_train,\n",
    "    y_train,\n",
    "    validation_data=(data_test, y_test),\n",
    "    epochs = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2f07725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917/2917 [==============================] - 6s 2ms/step - loss: 0.6290 - accuracy: 0.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6289677023887634, 0.8926199078559875]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    data_test,\n",
    "    y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
