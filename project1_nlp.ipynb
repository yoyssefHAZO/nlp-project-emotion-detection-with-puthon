{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5eb7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8100\\529907314.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('data1.txt',delimiter='\\;', header=None, names = ['comment', 'emotion'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "love        2692\n",
       "anger       2159\n",
       "fear        1937\n",
       "surprise    1905\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data1.txt',delimiter='\\;', header=None, names = ['comment', 'emotion'])\n",
    "# In feature engineering we will create 3 features (text_len),(punctuation_perc), and (capital_perc)\n",
    "import string\n",
    "#adding feature (text_len)\n",
    "data['body_len'] = data['comment'].apply(lambda i : len(i)-i.count(\" \"))\n",
    "data.emotion.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed3d482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub('[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub('\\d+', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the content column\n",
    "data['comment'] = data['comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3865b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[didnt, feel, humiliated]</td>\n",
       "      <td>sadness</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[im, grabbing, minute, post, feel, greedy, wrong]</td>\n",
       "      <td>anger</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "      <td>love</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[feeling, grouchy]</td>\n",
       "      <td>anger</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  emotion  body_len\n",
       "0                          [didnt, feel, humiliated]  sadness        20\n",
       "1  [go, feeling, hopeless, damned, hopeful, aroun...  sadness        88\n",
       "2  [im, grabbing, minute, post, feel, greedy, wrong]    anger        39\n",
       "3  [ever, feeling, nostalgic, fireplace, know, st...     love        75\n",
       "4                                 [feeling, grouchy]    anger        17"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Tokenization & Removing 'stop words' for training\n",
    "from nltk.tokenize import word_tokenize\n",
    "filtered_sentence_arr=[]\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "for example_sent in data['comment']:\n",
    "    word_tokens = word_tokenize(example_sent)\n",
    "    # converts the words in word_tokens to lower case and then checks whether\n",
    "    #they are present in stop_words or not\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(w.lower())\n",
    "    filtered_sentence_arr.append(filtered_sentence)\n",
    "data['comment']=filtered_sentence_arr\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7363395e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  emotion  body_len\n",
       "0                              didnt feel humiliated  sadness        20\n",
       "1  go feeling hopeless damned hopeful around some...  sadness        88\n",
       "2          im grabbing minute post feel greedy wrong    anger        39\n",
       "3  ever feeling nostalgic fireplace know still pr...     love        75\n",
       "4                                    feeling grouchy    anger        17"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second (Stemming) & (lemmitization) for training\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "arr1=[]\n",
    "arr2=[]\n",
    "for i in data['comment']:\n",
    "    arr1=[]\n",
    "    for j in i:\n",
    "        a=lemmatizer.lemmatize(j)\n",
    "        arr1.append(a)\n",
    "    arr2.append(\" \".join(arr1))\n",
    "data['comment']=arr2\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b0f5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting TF-IDF parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "xx = tfidf.fit_transform(data['comment'])\n",
    "\n",
    "#Training & Testing Encoding\n",
    "y = data.emotion.replace(to_replace=['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'], value=[0,1,2,3,4,5])\n",
    "x=pd.concat([data['body_len'],pd.DataFrame(xx)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6a75b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16848x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 130200 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting TF-IDF parameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(xx, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfce5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import KFold, cross_val_score\n",
    "#rf=RandomForestClassifier(n_jobs=-1)\n",
    "#k_fold = KFold(n_splits=5)\n",
    "#cross_val_score(rf,x,data['comment'],cv=k_fold, scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1dfa7d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes tfidf accuracy 0.6705819540843566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "acc_naive=accuracy_score(y_pred, y_test)\n",
    "print('naive bayes tfidf accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9f7f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest tfidf accuracy 0.7293112653497064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "acc_random=accuracy_score(y_pred, y_test)\n",
    "print('random forest tfidf accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1d20592",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\n",
    "# Extracting Count Vectors Parameters\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data['comment'])\n",
    "X_train_count =  count_vect.transform(x_train)\n",
    "X_val_count =  count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5e121b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.9113721302722905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "acc_lsvm=accuracy_score(y_pred, y_test)\n",
    "print('lsvm using count vectors accuracy %s' % x_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ea194b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.9113721302722905\n"
     ]
    }
   ],
   "source": [
    "print('lsvm using count vectors accuracy %s' % x_acc)\n",
    "arr_name={\n",
    "0:'sadness',\n",
    "1:'anger',\n",
    "2:'love',\n",
    "3:'surprise',\n",
    "4:'fear',\n",
    "5:'joy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bfe6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter end to end or enter example  :\n",
      "joy\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#example_sent='im grabbing a minute to post i feel greedy wrong'\n",
    "example_sent=input(\"enter end to end or enter example  :\")\n",
    "def word_test(example_sent):\n",
    "    #Tokenization & Removing 'stop words' for training\n",
    "    stop_words = stopwords.words('english')\n",
    "    word_tokens = word_tokenize(example_sent)\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(lemmatizer.lemmatize(w.lower()))\n",
    "            #a=lemmatizer.lemmatize(j)\n",
    "    filtered_sentence=\" \".join(filtered_sentence)\n",
    "    filtered_sentence=[filtered_sentence]\n",
    "    example_sent_count =  count_vect.transform(filtered_sentence)\n",
    "    y_pred = lsvm.predict(example_sent_count)\n",
    "    \n",
    "    x= arr_name[y_pred[0]]\n",
    "    print(x)\n",
    "    return x\n",
    "y_pred1=''\n",
    "y_pred1=word_test(example_sent)\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45063375",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"\"\"i didnt feel humiliated;sadness\n",
    "i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake;sadness\n",
    "im grabbing a minute to post i feel greedy wrong;anger\n",
    "i am ever feeling nostalgic about the fireplace i will know that it is still on the property;love\n",
    "i am feeling grouchy;anger\n",
    "ive been feeling a little burdened lately wasnt sure why that was;sadness\n",
    "ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny;surprise\n",
    "i feel as confused about life as a teenager or as jaded as a year old man;fear\n",
    "i have been with petronas for years i feel that petronas has performed well and made a huge profit;joy\n",
    "i feel romantic too;love\n",
    "i feel like i have to make the suffering i m seeing mean something;sadness\n",
    "i do feel that running is a divine experience and that i can expect to have some type of spiritual encounter;joy\n",
    "i think it s the easiest time of year to feel dissatisfied;anger\n",
    "i feel low energy i m just thirsty;sadness\n",
    "i have immense sympathy with the general point but as a possible proto writer trying to find time to write in the corners of life and with no sign of an agent let alone a publishing contract this feels a little precious;joy\n",
    "i do not feel reassured anxiety is on each side;joy\n",
    "i didnt really feel that embarrassed;sadness\n",
    "i feel pretty pathetic most of the time;sadness\n",
    "i started feeling sentimental about dolls i had as a child and so began a collection of vintage barbie dolls from the sixties;sadness\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a78e4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n"
     ]
    }
   ],
   "source": [
    "from  tkinter import *\n",
    "from  tkinter.ttk import Combobox\n",
    "#size\n",
    "w=500\n",
    "h=400\n",
    "#pos\n",
    "x=100\n",
    "y=100\n",
    "###################################################\n",
    "gui=Tk()\n",
    "model_name=[\"lsvm\",\"naive bayes\",\"random forest\"]\n",
    "name_model=StringVar()\n",
    "com=Combobox(gui,value=model_name,state='readonly',textvariable=name_model)\n",
    "###################################################show out\n",
    "def def_train():\n",
    "    example_sent=ent_k.get()\n",
    "    acc=word_test(example_sent)\n",
    "    lab_acc_v=Label(gui,text=acc,width=15,height=5,font=('Times',12))\n",
    "    lab_acc_v.grid(row=4,column=0,columnspan=2,padx=5)\n",
    "    #test.grid(row=3,column=1,columnspan=2 ,padx=10, pady=40)\n",
    "###################################################\n",
    "###################################################\n",
    "###################################################show out\n",
    "def def_train_1():\n",
    "    a=name_model.get()\n",
    "    if a=='lsvm':\n",
    "        acc_value=acc_lsvm\n",
    "    elif a=='naive bayes':\n",
    "        acc_value=acc_naive\n",
    "    elif a=='random forest':\n",
    "        acc_value=acc_random\n",
    "    else:\n",
    "        acc_value=100\n",
    "    modelacc=Label(gui,text=acc_value,font=('Times',12))\n",
    "    modelacc.grid(row=1,column=2,columnspan=2,pady=20)\n",
    "    #test.grid(row=3,column=1,columnspan=2 ,padx=10, pady=40)\n",
    "###################################################\n",
    "###################################################\n",
    "##########################################\n",
    "lab_w=Label(gui,text=\"Emotion System Project\",fg='red',width=18,height=5,font=('Times',15))\n",
    "lab_modelacc=Label(gui,text=\"model acc\",font=('Times',12))\n",
    "acc_value=x_acc\n",
    "modelacc=Label(gui,text=acc_value,font=('Times',12))\n",
    "lab_enter=Label(gui,text=\"enter the text\",font=('Times',12))\n",
    "#################################\n",
    "ent_k=Entry(gui)\n",
    "##############\n",
    "test=Button(gui,text='Test the model',command=def_train,font=('Times',12))\n",
    "show_acc=Button(gui,text='Show the acc',command=def_train_1,font=('Times',12))\n",
    "###################################\n",
    "lab_w.grid(row=0,column=0,columnspan=4, padx=150, pady=0)\n",
    "lab_modelacc.grid(row=1,column=0)\n",
    "#modelacc.grid(row=1,column=3,columnspan=2,pady=20)\n",
    "lab_enter.grid(row=2,column=0)\n",
    "ent_k.grid(row=2,column=2,columnspan=2)\n",
    "test.grid(row=3,column=0,columnspan=2 ,padx=10, pady=40)\n",
    "show_acc.grid(row=3,column=2,columnspan=2 ,padx=10, pady=40)\n",
    "com.grid(row=4,column=2,columnspan=2,padx=5)\n",
    "###################################\n",
    "gui.title(\"NLP PROJECT\")#title name\n",
    "gui.geometry(f\"{w}x{h}+{x}+{y}\")#size(num(w) x num(h))+ pos(num(x)+num(y))\n",
    "\n",
    "gui.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611d0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f14626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
